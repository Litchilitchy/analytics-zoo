{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we will use tensorflow.keras package to create a keras image classification application using model MobileNetV2, and transfer the application to Cluster Serving step by step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original Keras application\n",
    "We will first show an original Keras application, which download the data and preprocess it, then create the MobileNetV2 model to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Obtain data from url:\"https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\"\n",
    "zip_file = tf.keras.utils.get_file(origin=\"https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\",\n",
    "                                   fname=\"cats_and_dogs_filtered.zip\", extract=True)\n",
    "\n",
    "# Find the directory of validation set\n",
    "base_dir, _ = os.path.splitext(zip_file)\n",
    "test_dir = os.path.join(base_dir, 'validation')\n",
    "# Set images size to 160x160x3\n",
    "image_size = 160\n",
    "\n",
    "# Rescale all images by 1./255 and apply image augmentation\n",
    "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Flow images using generator to the test_generator\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "                test_dir,\n",
    "                target_size=(image_size, image_size),\n",
    "                batch_size=1,\n",
    "                class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the base model from the pre-trained model MobileNet V2\n",
    "IMG_SHAPE=(160,160,3)\n",
    "model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In keras, input could be ndarray, or generator. We could just use `model.predict(test_generator)`. But to simplify, here we just input the first record to model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "    0.0000000e+00 0.0000000e+00]\n",
      "   [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "    1.3335862e+00 0.0000000e+00]\n",
      "   [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "    2.3917289e+00 0.0000000e+00]\n",
      "   [0.0000000e+00 0.0000000e+00 1.5355210e+00 ... 0.0000000e+00\n",
      "    1.7352901e+00 0.0000000e+00]\n",
      "   [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "    0.0000000e+00 0.0000000e+00]]\n",
      "\n",
      "  [[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "    0.0000000e+00 0.0000000e+00]\n",
      "   [0.0000000e+00 0.0000000e+00 1.5430450e-03 ... 0.0000000e+00\n",
      "    2.6985502e-01 0.0000000e+00]\n",
      "   [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "    7.0699120e-01 0.0000000e+00]\n",
      "   [0.0000000e+00 0.0000000e+00 2.3603735e+00 ... 0.0000000e+00\n",
      "    2.1094999e+00 0.0000000e+00]\n",
      "   [0.0000000e+00 0.0000000e+00 1.4562187e+00 ... 0.0000000e+00\n",
      "    0.0000000e+00 0.0000000e+00]]\n",
      "\n",
      "  [[0.0000000e+00 0.0000000e+00 2.2438388e+00 ... 3.8799715e-01\n",
      "    0.0000000e+00 0.0000000e+00]\n",
      "   [0.0000000e+00 0.0000000e+00 2.2457170e+00 ... 6.0643148e-01\n",
      "    1.1573968e+00 0.0000000e+00]\n",
      "   [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "    1.9887586e+00 0.0000000e+00]\n",
      "   [0.0000000e+00 0.0000000e+00 1.2939215e+00 ... 2.8535223e-01\n",
      "    1.2313147e+00 2.5045009e+00]\n",
      "   [0.0000000e+00 0.0000000e+00 1.5868707e+00 ... 0.0000000e+00\n",
      "    0.0000000e+00 3.2710567e+00]]\n",
      "\n",
      "  [[0.0000000e+00 0.0000000e+00 1.3508234e+00 ... 1.1159754e-01\n",
      "    0.0000000e+00 2.4095855e+00]\n",
      "   [0.0000000e+00 0.0000000e+00 3.4443383e+00 ... 1.4259815e+00\n",
      "    0.0000000e+00 6.0000000e+00]\n",
      "   [0.0000000e+00 0.0000000e+00 2.0048237e-01 ... 0.0000000e+00\n",
      "    0.0000000e+00 6.0000000e+00]\n",
      "   [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 3.7185574e-01\n",
      "    0.0000000e+00 6.0000000e+00]\n",
      "   [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "    0.0000000e+00 4.8483086e+00]]\n",
      "\n",
      "  [[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "    0.0000000e+00 1.7216597e+00]\n",
      "   [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "    0.0000000e+00 4.9176378e+00]\n",
      "   [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "    0.0000000e+00 6.0000000e+00]\n",
      "   [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "    0.0000000e+00 5.1348572e+00]\n",
      "   [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "    0.0000000e+00 2.6994867e+00]]]]\n"
     ]
    }
   ],
   "source": [
    "prediction=model.predict(test_generator.next()[0])\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now the Keras application is completed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export TensorFlow Saved Model\n",
    "Next, we transfer the application to Cluster Serving. The first step is to save the model to SavedModel format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/litchy/anaconda3/envs/rec/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: transfer_learning_mobilenetv2/assets\n"
     ]
    }
   ],
   "source": [
    "# Save trained model to ./transfer_learning_mobilenetv2\n",
    "model.save('transfer_learning_mobilenetv2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy Cluster Serving\n",
    "After model prepared, we start to deploy it on Cluster Serving."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We config the model path in `config.yaml` to following (if you do not know what is `config.yaml`, check [Cluster Serving Configuration](https://github.com/intel-analytics/analytics-zoo/blob/master/docs/docs/ClusterServingGuide/ProgrammingGuide.md#2-configuration))\n",
    "```\n",
    "## Analytics-zoo Cluster Serving\n",
    "\n",
    "model:\n",
    "  # model path must be provided\n",
    "  path: /path/to/transfer_learning_mobilenetv2\n",
    "```\n",
    "\n",
    "\n",
    "After configuration, start Cluster Serving by `cluster-serving-start` as mentioned in [Cluster Serving Programming Guide](https://github.com/intel-analytics/analytics-zoo/blob/master/docs/docs/ClusterServingGuide/ProgrammingGuide.md#3-launching-service)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we start Cluster Serving code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zoo.serving.client import InputQueue, OutputQueue\n",
    "input_queue = InputQueue()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Cluster Serving, only NdArray is supported as input. Thus, we first transform the generator to ndarray (If you do not know how to transform your input to NdArray, you may get help at [data transform guide](https://github.com/intel-analytics/analytics-zoo/tree/master/docs/docs/ClusterServingGuide/OtherFrameworkUsers#data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.04705883, 0.        , 0.07450981],\n",
       "         [0.06666667, 0.05882353, 0.21568629],\n",
       "         [0.57254905, 0.68235296, 0.8705883 ],\n",
       "         ...,\n",
       "         [0.5176471 , 0.38823533, 0.21960786],\n",
       "         [0.4784314 , 0.3529412 , 0.19215688],\n",
       "         [0.48627454, 0.37254903, 0.20784315]],\n",
       "\n",
       "        [[0.12941177, 0.09803922, 0.25882354],\n",
       "         [0.38431376, 0.37647063, 0.52156866],\n",
       "         [0.8862746 , 0.9215687 , 0.9803922 ],\n",
       "         ...,\n",
       "         [0.4666667 , 0.36862746, 0.21176472],\n",
       "         [0.45882356, 0.3647059 , 0.21568629],\n",
       "         [0.45098042, 0.3647059 , 0.21960786]],\n",
       "\n",
       "        [[0.4901961 , 0.52156866, 0.5294118 ],\n",
       "         [0.54901963, 0.5529412 , 0.52156866],\n",
       "         [0.5294118 , 0.49803925, 0.35686275],\n",
       "         ...,\n",
       "         [0.41960788, 0.34509805, 0.21960786],\n",
       "         [0.43529415, 0.37254903, 0.24313727],\n",
       "         [0.4156863 , 0.35686275, 0.23529413]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.34901962, 0.47450984, 0.57254905],\n",
       "         [0.37647063, 0.5019608 , 0.6       ],\n",
       "         [0.3529412 , 0.4784314 , 0.5764706 ],\n",
       "         ...,\n",
       "         [0.6392157 , 0.7254902 , 0.8196079 ],\n",
       "         [0.58431375, 0.6666667 , 0.7490196 ],\n",
       "         [0.64705884, 0.7176471 , 0.80392164]],\n",
       "\n",
       "        [[0.47058827, 0.59607846, 0.69411767],\n",
       "         [0.49803925, 0.62352943, 0.72156864],\n",
       "         [0.36862746, 0.49411768, 0.5921569 ],\n",
       "         ...,\n",
       "         [0.5647059 , 0.6509804 , 0.74509805],\n",
       "         [0.6039216 , 0.68235296, 0.77647066],\n",
       "         [0.5921569 , 0.6627451 , 0.7411765 ]],\n",
       "\n",
       "        [[0.40000004, 0.49411768, 0.59607846],\n",
       "         [0.4156863 , 0.5254902 , 0.61960787],\n",
       "         [0.34901962, 0.48235297, 0.5803922 ],\n",
       "         ...,\n",
       "         [0.654902  , 0.7568628 , 0.854902  ],\n",
       "         [0.6       , 0.7019608 , 0.79215693],\n",
       "         [0.5764706 , 0.68235296, 0.76470596]]]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = test_generator.next()[0]\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use async api to put and get, you have pass a name arg and use the name to get\n",
    "input_queue.enqueue('my-input', arr)\n",
    "output_queue = OutputQueue()\n",
    "prediction = output_queue.query('my-input')\n",
    "# Use sync api to predict, this will block until the result is get or timeout\n",
    "prediction = input_queue.predict(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If everything works well, the result `prediction` would be the exactly the same NdArray object with the output of original Keras model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the end of this tutorial. If you have any question, you could raise an issue at [Analytics Zoo Github](https://github.com/intel-analytics/analytics-zoo/issues)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
